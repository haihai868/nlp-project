{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17c87cc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:25.365912Z",
     "iopub.status.busy": "2025-12-15T10:25:25.365663Z",
     "iopub.status.idle": "2025-12-15T10:25:32.352919Z",
     "shell.execute_reply": "2025-12-15T10:25:32.351987Z"
    },
    "id": "6DnsePCoxn4q",
    "papermill": {
     "duration": 6.997695,
     "end_time": "2025-12-15T10:25:32.354539",
     "exception": false,
     "start_time": "2025-12-15T10:25:25.356844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "from torch import Tensor\n",
    "import copy\n",
    "from pytz import timezone\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d44b50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:32.371394Z",
     "iopub.status.busy": "2025-12-15T10:25:32.371022Z",
     "iopub.status.idle": "2025-12-15T10:25:32.416785Z",
     "shell.execute_reply": "2025-12-15T10:25:32.416093Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1765371392600,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "hcVh4srsg09w",
    "outputId": "311e536c-ebf4-4738-877e-18b2af5d39d9",
    "papermill": {
     "duration": 0.055145,
     "end_time": "2025-12-15T10:25:32.417921",
     "exception": false,
     "start_time": "2025-12-15T10:25:32.362776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ab7bb25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:32.432501Z",
     "iopub.status.busy": "2025-12-15T10:25:32.432271Z",
     "iopub.status.idle": "2025-12-15T10:25:32.436987Z",
     "shell.execute_reply": "2025-12-15T10:25:32.436331Z"
    },
    "id": "oAiggILdg09x",
    "papermill": {
     "duration": 0.013584,
     "end_time": "2025-12-15T10:25:32.438209",
     "exception": false,
     "start_time": "2025-12-15T10:25:32.424625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Config\n",
    "class Config:\n",
    "  D_MODEL = 256\n",
    "  BATCH_SIZE = 16\n",
    "  MHA_NUMHEADS = 8\n",
    "\n",
    "  FF_DROPOUT = 0.15\n",
    "  MHA_DROPOUT = 0.15\n",
    "  PE_DROP_OUT = 0.15\n",
    "\n",
    "  # Position encoding\n",
    "  EPSILON_TERM = 1e-5\n",
    "\n",
    "  N_ENCODERS = 3\n",
    "  N_DECODERS = 3\n",
    "\n",
    "  #FF\n",
    "  FF_SCALE = 4\n",
    "\n",
    "  LEARNING_RATE = 1e-3\n",
    "\n",
    "\n",
    "config_dict = {k.lower(): v for k, v in Config.__dict__.items() if not k.startswith(\"__\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12c41014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:32.453501Z",
     "iopub.status.busy": "2025-12-15T10:25:32.453084Z",
     "iopub.status.idle": "2025-12-15T10:25:32.458205Z",
     "shell.execute_reply": "2025-12-15T10:25:32.457591Z"
    },
    "id": "sU_D_Pjdg09y",
    "papermill": {
     "duration": 0.014209,
     "end_time": "2025-12-15T10:25:32.459338",
     "exception": false,
     "start_time": "2025-12-15T10:25:32.445129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_subsequence_mask(size: int) -> Tensor:\n",
    "   # Cache to avoid regenerating masks\n",
    "   if not hasattr(generate_subsequence_mask, 'cache'):\n",
    "       generate_subsequence_mask.cache = {}\n",
    "\n",
    "   if size not in generate_subsequence_mask.cache:\n",
    "       mask_shape = (1, 1, size, size)\n",
    "       generate_subsequence_mask.cache[size] = torch.triu(torch.ones(mask_shape), 1).to(torch.bool)\n",
    "\n",
    "   return generate_subsequence_mask.cache[size]\n",
    "\n",
    "def generate_padding_mask(seq: Tensor, pad_id: int) -> Tensor:\n",
    "   return (seq == pad_id).unsqueeze(1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6846cb93",
   "metadata": {
    "id": "2-VdH5PE2a1F",
    "papermill": {
     "duration": 0.006646,
     "end_time": "2025-12-15T10:25:32.472723",
     "exception": false,
     "start_time": "2025-12-15T10:25:32.466077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ed70749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:32.487948Z",
     "iopub.status.busy": "2025-12-15T10:25:32.487421Z",
     "iopub.status.idle": "2025-12-15T10:25:32.491014Z",
     "shell.execute_reply": "2025-12-15T10:25:32.490465Z"
    },
    "id": "w9tSY4KG2d1b",
    "papermill": {
     "duration": 0.012381,
     "end_time": "2025-12-15T10:25:32.492001",
     "exception": false,
     "start_time": "2025-12-15T10:25:32.479620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLEAN_PATH = '../data/archive'\n",
    "\n",
    "EN2ID_DIR = CLEAN_PATH + \"/en_token2id.json\"\n",
    "ID2EN_DIR = CLEAN_PATH + \"/en_id2token.json\"\n",
    "VI2ID_DIR = CLEAN_PATH + \"/vi_token2id.json\"\n",
    "ID2VI_DIR = CLEAN_PATH + \"/vi_id2token.json\"\n",
    "TRAIN_DIR = CLEAN_PATH + \"/train.csv\"\n",
    "TEST_DIR = CLEAN_PATH + \"/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a0d0967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:32.506486Z",
     "iopub.status.busy": "2025-12-15T10:25:32.506047Z",
     "iopub.status.idle": "2025-12-15T10:25:33.942572Z",
     "shell.execute_reply": "2025-12-15T10:25:33.941932Z"
    },
    "executionInfo": {
     "elapsed": 1408,
     "status": "ok",
     "timestamp": 1765371394022,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "SxIeeiaW2icb",
    "outputId": "b7b86419-1521-4f91-e056-9288e392e6a2",
    "papermill": {
     "duration": 1.444848,
     "end_time": "2025-12-15T10:25:33.943743",
     "exception": false,
     "start_time": "2025-12-15T10:25:32.498895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15674, 3671, 10452, 2290)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_DIR)\n",
    "test_df = pd.read_csv(TEST_DIR)\n",
    "\n",
    "def load_json(path):\n",
    "  with open(path, \"r\") as f:\n",
    "    return json.load(f)\n",
    "\n",
    "en_token2id = load_json(EN2ID_DIR)\n",
    "en_id2token = load_json(ID2EN_DIR)\n",
    "vi_token2id = load_json(VI2ID_DIR)\n",
    "vi_id2token = load_json(ID2VI_DIR)\n",
    "\n",
    "EN_UNK_ID = en_token2id['<unk>']\n",
    "EN_PAD_ID = en_token2id['<pad>']\n",
    "EN_SOS_ID = en_token2id['<s>']\n",
    "EN_EOS_ID = en_token2id['</s>']\n",
    "\n",
    "EN_UNK_ID, EN_PAD_ID, EN_SOS_ID, EN_EOS_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcb2f8b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:33.958999Z",
     "iopub.status.busy": "2025-12-15T10:25:33.958285Z",
     "iopub.status.idle": "2025-12-15T10:25:33.974820Z",
     "shell.execute_reply": "2025-12-15T10:25:33.974221Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1765371394029,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "jdvmTMsYwhOp",
    "outputId": "d6a03d1b-42f7-43a1-c493-8ad16cec0a24",
    "papermill": {
     "duration": 0.025032,
     "end_time": "2025-12-15T10:25:33.975846",
     "exception": false,
     "start_time": "2025-12-15T10:25:33.950814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vi</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>làm sao tôi có thể trình bày trong 10 phút về ...</td>\n",
       "      <td>how can i speak in 10 minutes about the bonds ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>câu chuyện này chưa kết thúc .</td>\n",
       "      <td>this is not a finished story .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nó là một trò chơi ghép hình vẫn đang được xếp .</td>\n",
       "      <td>it is a jigsaw puzzle still being put together .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hãy để tôi kể cho các bạn về vài mảnh ghép nhé .</td>\n",
       "      <td>let me tell you about some of the pieces .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hãy tưởng tượng mảnh đầu tiên : một người đàn ...</td>\n",
       "      <td>imagine the first piece : a man burning his li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  vi  \\\n",
       "0  làm sao tôi có thể trình bày trong 10 phút về ...   \n",
       "1                     câu chuyện này chưa kết thúc .   \n",
       "2   nó là một trò chơi ghép hình vẫn đang được xếp .   \n",
       "3   hãy để tôi kể cho các bạn về vài mảnh ghép nhé .   \n",
       "4  hãy tưởng tượng mảnh đầu tiên : một người đàn ...   \n",
       "\n",
       "                                                  en  \n",
       "0  how can i speak in 10 minutes about the bonds ...  \n",
       "1                     this is not a finished story .  \n",
       "2   it is a jigsaw puzzle still being put together .  \n",
       "3         let me tell you about some of the pieces .  \n",
       "4  imagine the first piece : a man burning his li...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "606d9211",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:33.990683Z",
     "iopub.status.busy": "2025-12-15T10:25:33.990443Z",
     "iopub.status.idle": "2025-12-15T10:25:33.995017Z",
     "shell.execute_reply": "2025-12-15T10:25:33.994300Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1765371394035,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "QgU01cfswPwm",
    "outputId": "59a0c450-94bb-43fe-f6f6-8c6e9c3a8cb6",
    "papermill": {
     "duration": 0.013217,
     "end_time": "2025-12-15T10:25:33.996120",
     "exception": false,
     "start_time": "2025-12-15T10:25:33.982903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11217"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_token2id['i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "756b7e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:34.010405Z",
     "iopub.status.busy": "2025-12-15T10:25:34.010209Z",
     "iopub.status.idle": "2025-12-15T10:25:34.014798Z",
     "shell.execute_reply": "2025-12-15T10:25:34.014100Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1765371394039,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "kGBsJIjQ2mSM",
    "outputId": "51f1701c-0359-415e-9052-50a101cb7543",
    "papermill": {
     "duration": 0.012972,
     "end_time": "2025-12-15T10:25:34.015864",
     "exception": false,
     "start_time": "2025-12-15T10:25:34.002892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6450, 1488, 4270, 926)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VI_UNK_ID = vi_token2id['<unk>']\n",
    "VI_PAD_ID = vi_token2id['<pad>']\n",
    "VI_SOS_ID = vi_token2id['<s>']\n",
    "VI_EOS_ID = vi_token2id['</s>']\n",
    "\n",
    "VI_UNK_ID, VI_PAD_ID, VI_SOS_ID, VI_EOS_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "950acac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:34.030661Z",
     "iopub.status.busy": "2025-12-15T10:25:34.030449Z",
     "iopub.status.idle": "2025-12-15T10:25:34.034626Z",
     "shell.execute_reply": "2025-12-15T10:25:34.033929Z"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1765371394068,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "DKAT16Z-b6l5",
    "outputId": "d1669f2f-6600-4a2b-dc7c-cc6dcbf5e9dc",
    "papermill": {
     "duration": 0.012987,
     "end_time": "2025-12-15T10:25:34.035823",
     "exception": false,
     "start_time": "2025-12-15T10:25:34.022836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6469, 15722)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VI_VOCAB_LEN = len(vi_token2id)\n",
    "EN_VOCAB_LEN = len(en_token2id)\n",
    "VI_VOCAB_LEN, EN_VOCAB_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b87e03c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:34.050658Z",
     "iopub.status.busy": "2025-12-15T10:25:34.050272Z",
     "iopub.status.idle": "2025-12-15T10:25:34.056821Z",
     "shell.execute_reply": "2025-12-15T10:25:34.056121Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1765371394072,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "fOhUuF7R8uud",
    "outputId": "705fdb69-a76b-4f8e-d15c-5b4c54209dee",
    "papermill": {
     "duration": 0.015068,
     "end_time": "2025-12-15T10:25:34.057893",
     "exception": false,
     "start_time": "2025-12-15T10:25:34.042825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         rachel pike : the science behind a climate hea...\n",
       "1         in 4 minutes , atmospheric chemist rachel pike...\n",
       "2         i 'd like to talk to you today about the scale...\n",
       "3         headlines that look like this when they have t...\n",
       "4         they are both two branches of the same field o...\n",
       "                                ...                        \n",
       "132141    nelson mandela said , in the mid-2000s , not t...\n",
       "132142    it 's man-made and can be overcome and eradica...\n",
       "132143    i want to end by saying it 's been the actions...\n",
       "132144    didier sornette : how we can predict the next ...\n",
       "132145    the 2007-2008 financial crisis , you might thi...\n",
       "Name: en, Length: 132146, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a6a4d38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:34.073097Z",
     "iopub.status.busy": "2025-12-15T10:25:34.072903Z",
     "iopub.status.idle": "2025-12-15T10:25:35.662561Z",
     "shell.execute_reply": "2025-12-15T10:25:35.661837Z"
    },
    "executionInfo": {
     "elapsed": 1902,
     "status": "ok",
     "timestamp": 1765371395974,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "9ZW8BssL2odI",
    "outputId": "17e33a99-0f5a-4185-c309-8976cce560f4",
    "papermill": {
     "duration": 1.59878,
     "end_time": "2025-12-15T10:25:35.663709",
     "exception": false,
     "start_time": "2025-12-15T10:25:34.064929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vi</th>\n",
       "      <th>en</th>\n",
       "      <th>en_token</th>\n",
       "      <th>vi_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>khoa học đằng sau một tiêu đề về khí hậu</td>\n",
       "      <td>rachel pike : the science behind a climate hea...</td>\n",
       "      <td>[14036, 6875, 4951, 1240, 2785, 9591, 445, 735...</td>\n",
       "      <td>[3356, 1037, 1351, 2403, 700, 1344, 2233, 659,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trong 4 phút , chuyên gia hoá học khí quyển ra...</td>\n",
       "      <td>in 4 minutes , atmospheric chemist rachel pike...</td>\n",
       "      <td>[3135, 13964, 3090, 5018, 13738, 7975, 14036, ...</td>\n",
       "      <td>[3941, 5759, 6194, 2047, 244, 1009, 5709, 1037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tôi muốn cho các bạn biết về sự to lớn của nhữ...</td>\n",
       "      <td>i 'd like to talk to you today about the scale...</td>\n",
       "      <td>[15233, 9413, 5211, 3872, 2372, 3872, 11601, 1...</td>\n",
       "      <td>[5207, 2455, 5187, 884, 2936, 3620, 659, 2032,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>có những dòng trông như thế này khi bàn về biế...</td>\n",
       "      <td>headlines that look like this when they have t...</td>\n",
       "      <td>[9598, 858, 7035, 5211, 12727, 5285, 10660, 79...</td>\n",
       "      <td>[3208, 353, 1877, 5365, 5168, 2804, 6141, 3050...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cả hai đều là một nhánh của cùng một lĩnh vực ...</td>\n",
       "      <td>they are both two branches of the same field o...</td>\n",
       "      <td>[10660, 15009, 13993, 13554, 14517, 13894, 124...</td>\n",
       "      <td>[4722, 5280, 1107, 2849, 700, 2806, 4375, 2999...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  vi  \\\n",
       "0           khoa học đằng sau một tiêu đề về khí hậu   \n",
       "1  trong 4 phút , chuyên gia hoá học khí quyển ra...   \n",
       "2  tôi muốn cho các bạn biết về sự to lớn của nhữ...   \n",
       "3  có những dòng trông như thế này khi bàn về biế...   \n",
       "4  cả hai đều là một nhánh của cùng một lĩnh vực ...   \n",
       "\n",
       "                                                  en  \\\n",
       "0  rachel pike : the science behind a climate hea...   \n",
       "1  in 4 minutes , atmospheric chemist rachel pike...   \n",
       "2  i 'd like to talk to you today about the scale...   \n",
       "3  headlines that look like this when they have t...   \n",
       "4  they are both two branches of the same field o...   \n",
       "\n",
       "                                            en_token  \\\n",
       "0  [14036, 6875, 4951, 1240, 2785, 9591, 445, 735...   \n",
       "1  [3135, 13964, 3090, 5018, 13738, 7975, 14036, ...   \n",
       "2  [15233, 9413, 5211, 3872, 2372, 3872, 11601, 1...   \n",
       "3  [9598, 858, 7035, 5211, 12727, 5285, 10660, 79...   \n",
       "4  [10660, 15009, 13993, 13554, 14517, 13894, 124...   \n",
       "\n",
       "                                            vi_token  \n",
       "0  [3356, 1037, 1351, 2403, 700, 1344, 2233, 659,...  \n",
       "1  [3941, 5759, 6194, 2047, 244, 1009, 5709, 1037...  \n",
       "2  [5207, 2455, 5187, 884, 2936, 3620, 659, 2032,...  \n",
       "3  [3208, 353, 1877, 5365, 5168, 2804, 6141, 3050...  \n",
       "4  [4722, 5280, 1107, 2849, 700, 2806, 4375, 2999...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['en_token'] = train_df['en'].apply(lambda x: [en_token2id.get(token, EN_UNK_ID) for token in x.split()])\n",
    "train_df['vi_token'] = train_df['vi'].apply(lambda x: [vi_token2id.get(token, VI_UNK_ID) for token in x.split()])\n",
    "\n",
    "test_df['en_token'] = test_df['en'].apply(lambda x: [en_token2id.get(token, EN_UNK_ID) for token in x.split()])\n",
    "test_df['vi_token'] = test_df['vi'].apply(lambda x: [vi_token2id.get(token, VI_UNK_ID) for token in x.split()])\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd945edf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:35.679915Z",
     "iopub.status.busy": "2025-12-15T10:25:35.679693Z",
     "iopub.status.idle": "2025-12-15T10:25:35.688047Z",
     "shell.execute_reply": "2025-12-15T10:25:35.687447Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1765371395982,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "PZQ1P8_zHOsU",
    "outputId": "83bc4500-0b69-4b46-d0a6-8e5ef0d3bf53",
    "papermill": {
     "duration": 0.017535,
     "end_time": "2025-12-15T10:25:35.689132",
     "exception": false,
     "start_time": "2025-12-15T10:25:35.671597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132146, 776, 777)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)\n",
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47d6e1c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:35.704702Z",
     "iopub.status.busy": "2025-12-15T10:25:35.704467Z",
     "iopub.status.idle": "2025-12-15T10:25:35.714053Z",
     "shell.execute_reply": "2025-12-15T10:25:35.713485Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1765371395987,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "TyX9YkExyUbG",
    "outputId": "fc0e615e-5cb5-445c-b44f-fe9374a6b3f5",
    "papermill": {
     "duration": 0.018599,
     "end_time": "2025-12-15T10:25:35.715085",
     "exception": false,
     "start_time": "2025-12-15T10:25:35.696486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vi</th>\n",
       "      <th>en</th>\n",
       "      <th>en_token</th>\n",
       "      <th>vi_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>họ bán các chứng chỉ bảo mật</td>\n",
       "      <td>they sell certificates .</td>\n",
       "      <td>[10660, 6029, 11336, 13074]</td>\n",
       "      <td>[2384, 2503, 884, 1429, 5685, 661, 1505]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>ở đất nước của chúng ta , tại những bang miền ...</td>\n",
       "      <td>and yet , in this country , in the states of t...</td>\n",
       "      <td>[11391, 1590, 5018, 3135, 12727, 11972, 5018, ...</td>\n",
       "      <td>[5443, 2260, 5953, 4375, 2990, 555, 2047, 1804...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>và cuối cùng tôi quyết định tôi sẽ đến toà án ...</td>\n",
       "      <td>and i finally decided , oh gosh , i 've got to...</td>\n",
       "      <td>[11391, 15233, 4985, 8173, 5018, 5806, 5051, 5...</td>\n",
       "      <td>[3716, 4860, 2999, 5207, 3637, 1464, 5207, 177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>tôi bước vào xe , trong lòng cảm thấy rất rất ...</td>\n",
       "      <td>and i got into my car and i was feeling really...</td>\n",
       "      <td>[11391, 15233, 10101, 3913, 8950, 12932, 11391...</td>\n",
       "      <td>[5207, 231, 3007, 1028, 2047, 3941, 1475, 4611...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>bởi vì tôi nghĩ rằng cách duy nhất để hiểu đượ...</td>\n",
       "      <td>because i think the only way to understand thi...</td>\n",
       "      <td>[15601, 15233, 12550, 1240, 3099, 9256, 3872, ...</td>\n",
       "      <td>[5892, 1778, 5207, 3071, 1258, 6454, 742, 2899...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     vi  \\\n",
       "1522                       họ bán các chứng chỉ bảo mật   \n",
       "270   ở đất nước của chúng ta , tại những bang miền ...   \n",
       "353   và cuối cùng tôi quyết định tôi sẽ đến toà án ...   \n",
       "354   tôi bước vào xe , trong lòng cảm thấy rất rất ...   \n",
       "1050  bởi vì tôi nghĩ rằng cách duy nhất để hiểu đượ...   \n",
       "\n",
       "                                                     en  \\\n",
       "1522                           they sell certificates .   \n",
       "270   and yet , in this country , in the states of t...   \n",
       "353   and i finally decided , oh gosh , i 've got to...   \n",
       "354   and i got into my car and i was feeling really...   \n",
       "1050  because i think the only way to understand thi...   \n",
       "\n",
       "                                               en_token  \\\n",
       "1522                        [10660, 6029, 11336, 13074]   \n",
       "270   [11391, 1590, 5018, 3135, 12727, 11972, 5018, ...   \n",
       "353   [11391, 15233, 4985, 8173, 5018, 5806, 5051, 5...   \n",
       "354   [11391, 15233, 10101, 3913, 8950, 12932, 11391...   \n",
       "1050  [15601, 15233, 12550, 1240, 3099, 9256, 3872, ...   \n",
       "\n",
       "                                               vi_token  \n",
       "1522           [2384, 2503, 884, 1429, 5685, 661, 1505]  \n",
       "270   [5443, 2260, 5953, 4375, 2990, 555, 2047, 1804...  \n",
       "353   [3716, 4860, 2999, 5207, 3637, 1464, 5207, 177...  \n",
       "354   [5207, 231, 3007, 1028, 2047, 3941, 1475, 4611...  \n",
       "1050  [5892, 1778, 5207, 3071, 1258, 6454, 742, 2899...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff41ac4",
   "metadata": {
    "id": "FpdEv9jVekWQ",
    "papermill": {
     "duration": 0.007841,
     "end_time": "2025-12-15T10:25:35.730964",
     "exception": false,
     "start_time": "2025-12-15T10:25:35.723123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c7c90e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:35.747160Z",
     "iopub.status.busy": "2025-12-15T10:25:35.746767Z",
     "iopub.status.idle": "2025-12-15T10:25:35.752248Z",
     "shell.execute_reply": "2025-12-15T10:25:35.751540Z"
    },
    "id": "jxHUYc-G2o4j",
    "papermill": {
     "duration": 0.014777,
     "end_time": "2025-12-15T10:25:35.753243",
     "exception": false,
     "start_time": "2025-12-15T10:25:35.738466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LangDataset(Dataset):\n",
    "  def __init__(self, vi, en):\n",
    "    self.vi = [tokens + [VI_EOS_ID] for tokens in vi]\n",
    "    self.en_input = [[EN_SOS_ID] + tokens for tokens in en]\n",
    "    self.en_target = [tokens + [EN_EOS_ID] for tokens in en]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.vi)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return torch.tensor(self.vi[idx]), torch.tensor(self.en_input[idx]), torch.tensor(self.en_target[idx])\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "  vi_ts, en_in_ts, en_tar_ts = zip(*batch)\n",
    "  vi_ts = pad_sequence(vi_ts, batch_first=True, padding_value=VI_PAD_ID)\n",
    "  en_in_ts = pad_sequence(en_in_ts, batch_first=True, padding_value=EN_PAD_ID)\n",
    "  en_tar_ts = pad_sequence(en_tar_ts, batch_first=True, padding_value=EN_PAD_ID)\n",
    "  return vi_ts.to(device), en_in_ts.to(device), en_tar_ts.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c484e672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:35.769153Z",
     "iopub.status.busy": "2025-12-15T10:25:35.768952Z",
     "iopub.status.idle": "2025-12-15T10:25:36.519344Z",
     "shell.execute_reply": "2025-12-15T10:25:36.518430Z"
    },
    "id": "eLg1JJa62rqe",
    "papermill": {
     "duration": 0.760016,
     "end_time": "2025-12-15T10:25:36.520847",
     "exception": false,
     "start_time": "2025-12-15T10:25:35.760831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = LangDataset(train_df['vi_token'], train_df['en_token'])\n",
    "test_dataset = LangDataset(test_df['vi_token'], test_df['en_token'])\n",
    "val_dataset = LangDataset(val_df['vi_token'], val_df['en_token'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config_dict['batch_size'], collate_fn=collate_fn, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config_dict['batch_size'], collate_fn=collate_fn, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config_dict['batch_size'], collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385783fa",
   "metadata": {
    "id": "27cCdPB8eXyC",
    "papermill": {
     "duration": 0.007636,
     "end_time": "2025-12-15T10:25:36.536655",
     "exception": false,
     "start_time": "2025-12-15T10:25:36.529019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89275916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:36.552973Z",
     "iopub.status.busy": "2025-12-15T10:25:36.552744Z",
     "iopub.status.idle": "2025-12-15T10:25:37.048760Z",
     "shell.execute_reply": "2025-12-15T10:25:37.047863Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1765371396439,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "5ulfZz_ExQbt",
    "outputId": "c63b77a0-c444-4520-b8b5-bb830afc116f",
    "papermill": {
     "duration": 0.505878,
     "end_time": "2025-12-15T10:25:37.050107",
     "exception": false,
     "start_time": "2025-12-15T10:25:36.544229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHA forward flow with masks working\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from torch import Tensor\n",
    "import copy\n",
    "\n",
    "# @title Multi-head attention\n",
    "class MultiHeadAttention(nn.Module):\n",
    "  def __init__(self, d_model, num_heads, dropout):\n",
    "    super().__init__()\n",
    "\n",
    "    assert d_model % num_heads == 0, \"out_dim must be divisible by num_heads\"\n",
    "    self.num_heads = num_heads\n",
    "    self.d_k = d_model // num_heads\n",
    "    self.sqrt_dk = math.sqrt(self.d_k) # for scaled dot product\n",
    "\n",
    "    self.W_query = nn.Linear(d_model, d_model, bias=False)\n",
    "    self.W_key = nn.Linear(d_model, d_model, bias=False)\n",
    "    self.W_value = nn.Linear(d_model, d_model, bias=False)\n",
    "    self.out_proj = nn.Linear(d_model, d_model)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, query: Tensor, key: Tensor, value:Tensor, attn_mask=None, key_padding_mask=None)->Tensor:\n",
    "    # (batch_size, query_seq_len, d_model)\n",
    "    batch_size, query_seq_len, _ = query.shape\n",
    "\n",
    "    # Self-attention: q=k=v\n",
    "    if key is None: key = query\n",
    "    if value is None: value = query\n",
    "\n",
    "    key_seq_len = key.shape[1]\n",
    "    value_seq_len = value.shape[1]\n",
    "\n",
    "    Q = self.W_query(query)\n",
    "    K = self.W_key(key)\n",
    "    V = self.W_value(value)\n",
    "\n",
    "    # split head (batch_size, seq_len, num_heads, d_k)\n",
    "    Q = Q.view(batch_size, query_seq_len, self.num_heads, self.d_k)\n",
    "    K = K.view(batch_size, key_seq_len, self.num_heads, self.d_k)\n",
    "    V = V.view(batch_size, value_seq_len, self.num_heads, self.d_k)\n",
    "\n",
    "    attn_output = self.scaled_dot_product_attention(Q, K, V, attn_mask=attn_mask, key_padding_mask=key_padding_mask)\n",
    "\n",
    "    # (batch_size, num_heads, query_seq_len, d_k) -> (batch_size, query_seq_len, num_heads, d_k)\n",
    "    attn_output = attn_output.transpose(1, 2).contiguous()\n",
    "\n",
    "    # concat head (output sequence length matches query sequence length)\n",
    "    joined_heads = attn_output.reshape(batch_size, query_seq_len, -1)\n",
    "\n",
    "    out = self.out_proj(joined_heads)\n",
    "    out = self.dropout(out)\n",
    "    del Q, K, V, attn_output, joined_heads\n",
    "    return out\n",
    "\n",
    "  def scaled_dot_product_attention(self, Q: Tensor, K: Tensor, V: Tensor, attn_mask = None, key_padding_mask = None) -> Tensor:\n",
    "    \"\"\"\n",
    "        Q: (batch_size, query_seq_len, num_heads, d_k)\n",
    "        K: (batch_size, key_seq_len, num_heads, d_k)\n",
    "        V: (batch_size, value_seq_len, num_heads, d_k)\n",
    "        Returns:\n",
    "         attention_output: (batch_size, num_heads, query_seq_len, d_k)\n",
    "    \"\"\"\n",
    "    Q = Q.transpose(-2,-3)\n",
    "    K = K.transpose(-2,-3)\n",
    "    V = V.transpose(-2,-3)\n",
    "    # 1. S = (q * kT)/sqrt(d_k)\n",
    "    S = Q @ K.transpose(-1,-2) / self.sqrt_dk # (batch_size, num_heads, query_seq_len, key_seq_len)\n",
    "\n",
    "    # Combine masks\n",
    "    final_mask = None\n",
    "    if key_padding_mask is not None:\n",
    "      # key_padding_mask is (batch_size, 1, 1, key_seq_len)\n",
    "      # It needs to be broadcastable with S, which means masking the last dimension (key_seq_len)\n",
    "      final_mask = key_padding_mask\n",
    "\n",
    "    if attn_mask is not None:\n",
    "      # attn_mask is (1, 1, query_seq_len, key_seq_len)\n",
    "      if final_mask is None:\n",
    "        final_mask = attn_mask\n",
    "      else:\n",
    "        # Combine existing mask with attn_mask using logical OR\n",
    "        final_mask = final_mask | attn_mask\n",
    "\n",
    "    # Apply the combined mask\n",
    "    if final_mask is not None:\n",
    "      S = S.masked_fill(final_mask, float('-inf'))\n",
    "\n",
    "    # 3. attention_weights = softmax(S)\n",
    "    attn_weights = torch.softmax(S, dim=-1)\n",
    "    # 4. Dropout\n",
    "    attn_weights = self.dropout(attn_weights)\n",
    "    # 5. attention_ouput = attention_weights * V\n",
    "    return attn_weights @ V\n",
    "\n",
    "\n",
    "# ------------------ test --------------------\n",
    "def MHA_test():\n",
    "  _batch_size = Config.BATCH_SIZE\n",
    "  _seq_len = 128\n",
    "  _emb_dim = Config.D_MODEL\n",
    "  _num_head = Config.MHA_NUMHEADS\n",
    "\n",
    "  # Changed: Move mha to device\n",
    "  mha = MultiHeadAttention(_emb_dim , _num_head, 0).to(device)\n",
    "\n",
    "  query_cpu = key_cpu = value_cpu = torch.rand(_batch_size, _num_head, _seq_len, _emb_dim//_num_head)\n",
    "  unroll_cpu = query_cpu.transpose(1,2)\n",
    "  # The line below is for testing the internal SDP attention separately, might not fully reflect the device issue\n",
    "  # my_impl = mha.scaled_dot_product_attention(unroll.to(device), unroll.to(device), unroll.to(device))\n",
    "\n",
    "  # Test the full forward pass with a dummy mask\n",
    "  reshaped = unroll_cpu.reshape(_batch_size, _seq_len, -1).to(device) # Also move input to device\n",
    "  dummy_attn_mask = generate_subsequence_mask(_seq_len).to(device)\n",
    "  dummy_padding_mask = generate_padding_mask(torch.zeros(_batch_size, _seq_len).long(), 0).to(device) # Example: pad_id 0\n",
    "\n",
    "  mha_output_with_masks = mha.forward(reshaped, reshaped, reshaped, attn_mask=dummy_attn_mask, key_padding_mask=dummy_padding_mask)\n",
    "  if mha_output_with_masks.size() == reshaped.shape:\n",
    "    print(\"MHA forward flow with masks working\")\n",
    "MHA_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82f3abfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:37.067317Z",
     "iopub.status.busy": "2025-12-15T10:25:37.066918Z",
     "iopub.status.idle": "2025-12-15T10:25:37.093058Z",
     "shell.execute_reply": "2025-12-15T10:25:37.092278Z"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1765371396475,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "JNpIOzS-VNmj",
    "outputId": "4ad38e6c-31c5-4aa6-a785-d1d4a7d4b02f",
    "papermill": {
     "duration": 0.036028,
     "end_time": "2025-12-15T10:25:37.094374",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.058346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GQA forward flow with masks working\n"
     ]
    }
   ],
   "source": [
    "#@title Grouped Query Attention\n",
    "class GroupedQueryAttention(nn.Module):\n",
    "  def __init__(self, d_model, num_heads, dropout, num_groups = 4):\n",
    "    super().__init__()\n",
    "\n",
    "    assert d_model % num_heads == 0, \"out_dim must be divisible by num_heads\"\n",
    "    assert num_heads % num_groups == 0, \"num_heads must be divisible by num_groups\"\n",
    "    self.head_dim = d_model // num_heads\n",
    "    self.sqrt_dk = math.sqrt(self.head_dim) # for scaled dot product\n",
    "    self.num_groups = num_groups\n",
    "    self.num_q_heads = num_heads\n",
    "    self.num_kv_heads = num_heads // num_groups\n",
    "\n",
    "    self.W_query = nn.Linear(d_model, self.num_q_heads * self.head_dim, bias=False)\n",
    "    self.W_key = nn.Linear(d_model, self.num_kv_heads * self.head_dim, bias=False)\n",
    "    self.W_value = nn.Linear(d_model, self.num_kv_heads * self.head_dim, bias=False)\n",
    "    self.out_proj = nn.Linear(d_model, d_model)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, query: Tensor, key: Tensor, value:Tensor, attn_mask=None, key_padding_mask=None)->Tensor:\n",
    "    # (batch_size, query_seq_len, d_model)\n",
    "    batch_size, query_seq_len, _ = query.shape\n",
    "\n",
    "    # Self-attention: q=k=v\n",
    "    if key is None: key = query\n",
    "    if value is None: value = query\n",
    "\n",
    "    key_seq_len = key.shape[1]\n",
    "    value_seq_len = value.shape[1]\n",
    "\n",
    "    Q = self.W_query(query)\n",
    "    K = self.W_key(key)\n",
    "    V = self.W_value(value)\n",
    "\n",
    "    # split head (batch_size, seq_len, num_heads, head_dim)\n",
    "    Q = Q.view(batch_size, query_seq_len, self.num_q_heads, self.head_dim)\n",
    "    K = K.view(batch_size, key_seq_len, self.num_kv_heads, self.head_dim)\n",
    "    V = V.view(batch_size, value_seq_len, self.num_kv_heads, self.head_dim)\n",
    "\n",
    "    K, V = self._replicate_kv_heads(K, V)\n",
    "\n",
    "    attn_output = self.scaled_dot_product_attention(Q, K, V, attn_mask=attn_mask, key_padding_mask=key_padding_mask)\n",
    "\n",
    "    # (batch_size, num_heads, query_seq_len, head_dim) -> (batch_size, query_seq_len, num_heads, head_dim)\n",
    "    attn_output = attn_output.transpose(1, 2).contiguous()\n",
    "\n",
    "    # concat head (output sequence length matches query sequence length)\n",
    "    joined_heads = attn_output.reshape(batch_size, query_seq_len, -1)\n",
    "\n",
    "    out = self.out_proj(joined_heads)\n",
    "    out = self.dropout(out)\n",
    "    del Q, K, V, attn_output, joined_heads\n",
    "    return out\n",
    "  def _replicate_kv_heads(self, K: Tensor, V: Tensor) -> tuple[Tensor, Tensor]:\n",
    "      \"\"\"\n",
    "         K: (batch_size, key_seq_len, num_kv_heads, head_dim)\n",
    "         V: (batch_size, value_seq_len, num_kv_heads, head_dim)\n",
    "         Returns:\n",
    "         replicated_K: (batch_size, key_seq_len, num_q_heads, head_dim)\n",
    "         replicated_V: (batch_size, value_seq_len, num_q_heads, head_dim)\n",
    "      \"\"\"\n",
    "      batch_size, key_seq_len, num_kv_heads, head_dim = K.shape\n",
    "      _, value_seq_len, _, _ = V.shape\n",
    "\n",
    "      # Repeat each kv head num_groups times then reshape back\n",
    "      replicated_K = K.unsqueeze(2).repeat(1, 1, self.num_groups, 1, 1).reshape(batch_size, key_seq_len, self.num_q_heads, head_dim)\n",
    "      replicated_V = V.unsqueeze(2).repeat(1, 1, self.num_groups, 1, 1).reshape(batch_size, value_seq_len, self.num_q_heads, head_dim)\n",
    "\n",
    "      return replicated_K, replicated_V\n",
    "  def scaled_dot_product_attention(self, Q: Tensor, K: Tensor, V: Tensor, attn_mask = None, key_padding_mask = None) -> Tensor:\n",
    "    \"\"\"\n",
    "        Q: (batch_size, query_seq_len, num_heads, head_dim)\n",
    "        K: (batch_size, key_seq_len, num_heads, head_dim)\n",
    "        V: (batch_size, value_seq_len, num_heads, head_dim)\n",
    "        Returns:\n",
    "         attention_output: (batch_size, num_heads, query_seq_len, d_k)\n",
    "    \"\"\"\n",
    "    Q = Q.transpose(-2,-3)\n",
    "    K = K.transpose(-2,-3)\n",
    "    V = V.transpose(-2,-3)\n",
    "    # 1. S = (q * kT)/sqrt(d_k)\n",
    "    S = Q @ K.transpose(-1,-2) / self.sqrt_dk # (batch_size, num_heads, query_seq_len, key_seq_len)\n",
    "\n",
    "    # Combine masks\n",
    "    final_mask = None\n",
    "    if key_padding_mask is not None:\n",
    "      # key_padding_mask is (batch_size, 1, 1, key_seq_len)\n",
    "      # It needs to be broadcastable with S, which means masking the last dimension (key_seq_len)\n",
    "      final_mask = key_padding_mask\n",
    "\n",
    "    if attn_mask is not None:\n",
    "      # attn_mask is (1, 1, query_seq_len, key_seq_len)\n",
    "      if final_mask is None:\n",
    "        final_mask = attn_mask\n",
    "      else:\n",
    "        # Combine existing mask with attn_mask using logical OR\n",
    "        final_mask = final_mask | attn_mask\n",
    "\n",
    "    # Apply the combined mask\n",
    "    if final_mask is not None:\n",
    "      S = S.masked_fill(final_mask, float('-inf'))\n",
    "\n",
    "    # 3. attention_weights = softmax(S)\n",
    "    attn_weights = torch.softmax(S, dim=-1)\n",
    "    # 4. Dropout\n",
    "    attn_weights = self.dropout(attn_weights)\n",
    "    # 5. attention_ouput = attention_weights * V\n",
    "    return attn_weights @ V\n",
    "\n",
    "\n",
    "# ------------------ test --------------------\n",
    "def GQA_test():\n",
    "  _batch_size = Config.BATCH_SIZE\n",
    "  _seq_len = 128\n",
    "  _emb_dim = Config.D_MODEL\n",
    "  _num_head = Config.MHA_NUMHEADS\n",
    "\n",
    "  # Changed: Move mha to device\n",
    "  mha = GroupedQueryAttention(_emb_dim , _num_head, 0).to(device)\n",
    "\n",
    "  query_cpu = key_cpu = value_cpu = torch.rand(_batch_size, _num_head, _seq_len, _emb_dim//_num_head)\n",
    "  unroll_cpu = query_cpu.transpose(1,2)\n",
    "  # The line below is for testing the internal SDP attention separately, might not fully reflect the device issue\n",
    "  # my_impl = mha.scaled_dot_product_attention(unroll.to(device), unroll.to(device), unroll.to(device))\n",
    "\n",
    "  # Test the full forward pass with a dummy mask\n",
    "  reshaped = unroll_cpu.reshape(_batch_size, _seq_len, -1).to(device) # Also move input to device\n",
    "  dummy_attn_mask = generate_subsequence_mask(_seq_len).to(device)\n",
    "  dummy_padding_mask = generate_padding_mask(torch.zeros(_batch_size, _seq_len).long(), 0).to(device) # Example: pad_id 0\n",
    "\n",
    "  mha_output_with_masks = mha.forward(reshaped, reshaped, reshaped, attn_mask=dummy_attn_mask, key_padding_mask=dummy_padding_mask)\n",
    "  if mha_output_with_masks.size() == reshaped.shape:\n",
    "    print(\"GQA forward flow with masks working\")\n",
    "GQA_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9ec2ae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:37.112760Z",
     "iopub.status.busy": "2025-12-15T10:25:37.112292Z",
     "iopub.status.idle": "2025-12-15T10:25:37.117793Z",
     "shell.execute_reply": "2025-12-15T10:25:37.117056Z"
    },
    "id": "X8vMgbwzg09z",
    "papermill": {
     "duration": 0.015076,
     "end_time": "2025-12-15T10:25:37.119011",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.103935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Positional Embedding\n",
    "class PositionEmbedding(nn.Module):\n",
    "   \"\"\"\n",
    "   Sinusoidal Position Embedding.\n",
    "   \"\"\"\n",
    "   def __init__(self, d_model, max_len=5000, dropout: float = 0):\n",
    "      super().__init__()\n",
    "      assert d_model % 2 ==0, \"d_model must be divisible by 2\"\n",
    "\n",
    "      self.max_len = max_len\n",
    "      self.d_model = d_model\n",
    "\n",
    "      pe = torch.zeros(max_len, d_model)\n",
    "      position = torch.arange(0, max_len).unsqueeze(1) # (max_len, 1)\n",
    "      div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)) # (d_model/2)\n",
    "\n",
    "      pe[:, 0::2] = torch.sin(position * div_term)\n",
    "      pe[:, 1::2] = torch.cos(position * div_term)\n",
    "      pe = pe.unsqueeze(0)\n",
    "\n",
    "      # div_term = 10000.0 ** (torch.arange(0, d_model, 2) / d_model)\n",
    "\n",
    "      # pe[:, 0::2] = torch.sin(position / div_term)\n",
    "      # pe[:, 1::2] = torch.cos(position / div_term)\n",
    "\n",
    "      self.register_buffer(\"pe\", pe)\n",
    "      self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "   def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28edc778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:37.135369Z",
     "iopub.status.busy": "2025-12-15T10:25:37.135169Z",
     "iopub.status.idle": "2025-12-15T10:25:37.142180Z",
     "shell.execute_reply": "2025-12-15T10:25:37.141697Z"
    },
    "id": "RtD7dstAyOOG",
    "papermill": {
     "duration": 0.016235,
     "end_time": "2025-12-15T10:25:37.143110",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.126875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Layer Norm\n",
    "class LayerNorm(nn.Module):\n",
    "  def __init__(self, d_model):\n",
    "    super().__init__()\n",
    "    self.eps = Config.EPSILON_TERM\n",
    "    self.gamma = nn.Parameter(torch.ones(d_model)) # quyết định scale\n",
    "    self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "  def forward(self, x: Tensor) -> Tensor:\n",
    "    mean = x.mean(dim=-1, keepdim=True)\n",
    "    var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "    x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
    "    return x_norm * self.gamma + self.beta\n",
    "\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "  def __init__(self, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    self.eps = Config.EPSILON_TERM\n",
    "    self.gamma = nn.Parameter(torch.ones(d_model)) # quyết định scale\n",
    "    self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "  def forward(self, x: Tensor) -> Tensor:\n",
    "    rms = torch.sqrt((x * x).mean(dim=-1, keepdim=True) + self.eps)\n",
    "    return (x / rms) * self.gamma + self.beta\n",
    "\n",
    "class NormWrapper(nn.Module):\n",
    "    def __init__(self, d_model, norm_type=\"rms\"):\n",
    "        \"\"\"\n",
    "        norm_type:\n",
    "          \"layer\" -> LayerNorm\n",
    "          \"rms\"   -> RMSNorm\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if norm_type == \"layer\":\n",
    "            self.norm = LayerNorm(d_model)\n",
    "        elif norm_type == \"rms\":\n",
    "            self.norm = RMSNorm(d_model)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown norm_type: {norm_type}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12872e2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:37.159473Z",
     "iopub.status.busy": "2025-12-15T10:25:37.159278Z",
     "iopub.status.idle": "2025-12-15T10:25:37.163538Z",
     "shell.execute_reply": "2025-12-15T10:25:37.163027Z"
    },
    "id": "bVlhuznoyYS5",
    "papermill": {
     "duration": 0.013629,
     "end_time": "2025-12-15T10:25:37.164574",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.150945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FeedForwardLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        # LLaMA-style SwiGLU\n",
    "        self.w1 = nn.Linear(d_model, d_ff, bias=False)\n",
    "        self.w3 = nn.Linear(d_model, d_ff, bias=False)\n",
    "        self.w2 = nn.Linear(d_ff, d_model, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(\n",
    "            self.w2(\n",
    "                F.silu(self.w3(x)) * self.w1(x)\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "890b812c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:37.180995Z",
     "iopub.status.busy": "2025-12-15T10:25:37.180804Z",
     "iopub.status.idle": "2025-12-15T10:25:37.186296Z",
     "shell.execute_reply": "2025-12-15T10:25:37.185811Z"
    },
    "id": "64iweMIQut3b",
    "papermill": {
     "duration": 0.014885,
     "end_time": "2025-12-15T10:25:37.187316",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.172431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Encoder\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "  def __init__(self, d_model, dropout):\n",
    "    super().__init__()\n",
    "    self.norm1 = NormWrapper(d_model)\n",
    "    self.mh_self_attn = GroupedQueryAttention(d_model, Config.MHA_NUMHEADS, dropout)\n",
    "    self.norm2 = NormWrapper(d_model)\n",
    "    self.ff = FeedForwardLayer(d_model, d_model * 4, dropout)\n",
    "\n",
    "  def forward(self, x, src_padding_mask=None):\n",
    "    x_norm = self.norm1(x)\n",
    "    # Pass src_padding_mask to self-attention\n",
    "    mh_self_attn_o = self.mh_self_attn(x_norm, x_norm, x_norm, key_padding_mask=src_padding_mask)\n",
    "    x = x + mh_self_attn_o\n",
    "    x_norm = self.norm2(x)\n",
    "    ff_o = self.ff(x_norm)\n",
    "    return x + ff_o\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, d_model, n_layers, dropout):\n",
    "    super().__init__()\n",
    "    encoder_layer = EncoderLayer(d_model, dropout)\n",
    "    self.layers = nn.ModuleList([\n",
    "      copy.deepcopy(encoder_layer)\n",
    "      for _ in range(0, n_layers)\n",
    "    ])\n",
    "    self.norm = NormWrapper(d_model)\n",
    "\n",
    "  def forward(self, x, src_padding_mask=None):\n",
    "    for layer in self.layers:\n",
    "      # Pass src_padding_mask to each encoder layer\n",
    "      x = layer(x, src_padding_mask)\n",
    "    return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d337f2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:37.203966Z",
     "iopub.status.busy": "2025-12-15T10:25:37.203741Z",
     "iopub.status.idle": "2025-12-15T10:25:37.210728Z",
     "shell.execute_reply": "2025-12-15T10:25:37.210012Z"
    },
    "id": "0_83067h0qa2",
    "papermill": {
     "duration": 0.016598,
     "end_time": "2025-12-15T10:25:37.211754",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.195156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Decoder\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "  def __init__(self, d_model, dropout, decoder_only = False):\n",
    "    super().__init__()\n",
    "    self.decoder_only = decoder_only\n",
    "    self.norm1 = NormWrapper(d_model)\n",
    "    self.masked_self_attn = GroupedQueryAttention(d_model, Config.MHA_NUMHEADS, dropout)\n",
    "    if not decoder_only:\n",
    "      self.norm2 = NormWrapper(d_model)\n",
    "      self.cross_attn = GroupedQueryAttention(d_model, Config.MHA_NUMHEADS, dropout)\n",
    "    self.norm3 = NormWrapper(d_model)\n",
    "    self.ff = FeedForwardLayer(d_model, d_model * Config.FF_SCALE, dropout)\n",
    "\n",
    "  def forward(self, x, encoder_memory = None, target_mask =None, memory_mask = None, target_padding_mask=None, memory_padding_mask=None ):\n",
    "    x_norm = self.norm1(x)\n",
    "    # Pass target_mask (look-ahead) and target_padding_mask to masked self-attention\n",
    "    masked_self_attn_o = self.masked_self_attn(x_norm ,x_norm, x_norm, attn_mask=target_mask, key_padding_mask=target_padding_mask)\n",
    "    x = x + masked_self_attn_o # Changed from x += masked_self_attn_o\n",
    "\n",
    "    if not self.decoder_only:\n",
    "      assert encoder_memory is not None, \"Require encoder_memory parameter for encoder-decoder model\"\n",
    "      x_norm = self.norm2(x)\n",
    "      # Pass memory_mask (encoder output padding mask) to cross-attention\n",
    "      cross_attn_o = self.cross_attn(x_norm, encoder_memory, encoder_memory, key_padding_mask=memory_padding_mask)\n",
    "      x = x + cross_attn_o # Changed from x += cross_attn_o\n",
    "\n",
    "    x_norm = self.norm3(x)\n",
    "    ff_o = self.ff(x_norm)\n",
    "    return x + ff_o # Changed from x += ff_o\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, d_model, n_layers, dropout, decoder_only=False):\n",
    "    super().__init__()\n",
    "    decoder_layer = DecoderLayer(d_model, dropout, decoder_only)\n",
    "    self.layers = nn.ModuleList([\n",
    "      copy.deepcopy(decoder_layer)\n",
    "      for _ in range(0, n_layers)\n",
    "    ])\n",
    "    self.norm = NormWrapper(d_model)\n",
    "\n",
    "\n",
    "  def forward(self, x, encoder_memory, target_mask=None, memory_mask=None, target_padding_mask=None, memory_padding_mask=None ):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x, encoder_memory, target_mask, memory_mask, target_padding_mask, memory_padding_mask)\n",
    "    return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08ef37bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:37.228149Z",
     "iopub.status.busy": "2025-12-15T10:25:37.227957Z",
     "iopub.status.idle": "2025-12-15T10:25:37.231522Z",
     "shell.execute_reply": "2025-12-15T10:25:37.231019Z"
    },
    "id": "bJKzgaK8g093",
    "papermill": {
     "duration": 0.012857,
     "end_time": "2025-12-15T10:25:37.232549",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.219692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Generator\n",
    "\n",
    "class Generator(nn.Module):\n",
    "   def __init__(self, d_model, vocab_size) -> None:\n",
    "      super().__init__()\n",
    "      self.proj = nn.Linear(d_model, vocab_size)\n",
    "   def forward(self, x):\n",
    "      logits = self.proj(x)\n",
    "      return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8c22b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:37.249065Z",
     "iopub.status.busy": "2025-12-15T10:25:37.248874Z",
     "iopub.status.idle": "2025-12-15T10:25:37.252611Z",
     "shell.execute_reply": "2025-12-15T10:25:37.252087Z"
    },
    "id": "xDzPlxX2g094",
    "papermill": {
     "duration": 0.013396,
     "end_time": "2025-12-15T10:25:37.253714",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.240318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Embedding\n",
    "class Embedding(nn.Module):\n",
    "   def __init__(self, d_model, vocab_size) -> None:\n",
    "      super().__init__()\n",
    "      self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "      self.d_model = d_model\n",
    "   def forward(self, x):\n",
    "      \"\"\"\n",
    "         https://arxiv.org/pdf/1608.05859\n",
    "      \"\"\"\n",
    "      return self.embedding(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0343d3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:37.270597Z",
     "iopub.status.busy": "2025-12-15T10:25:37.270015Z",
     "iopub.status.idle": "2025-12-15T10:25:37.273773Z",
     "shell.execute_reply": "2025-12-15T10:25:37.273193Z"
    },
    "id": "s45GZVLAg094",
    "papermill": {
     "duration": 0.013095,
     "end_time": "2025-12-15T10:25:37.274767",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.261672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_total_params(model: nn.Module, name: str):\n",
    "   pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "   print(f\"{name} initialized with {pytorch_total_params:,} params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43088ba1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:37.291401Z",
     "iopub.status.busy": "2025-12-15T10:25:37.291032Z",
     "iopub.status.idle": "2025-12-15T10:25:37.296760Z",
     "shell.execute_reply": "2025-12-15T10:25:37.296174Z"
    },
    "id": "fbmOVRB0g094",
    "papermill": {
     "duration": 0.015183,
     "end_time": "2025-12-15T10:25:37.297862",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.282679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "   def __init__(self, d_model, tgt_vocab_size, src_embed, tgt_embed, n_encoders, n_decoders) -> None:\n",
    "      super().__init__()\n",
    "\n",
    "      self.d_model = d_model\n",
    "\n",
    "      self.src_embed = src_embed\n",
    "      self.tgt_embed = tgt_embed\n",
    "\n",
    "      # Corrected: Pass the dropout rate from Config\n",
    "      self.encoder = Encoder(d_model, n_encoders, Config.FF_DROPOUT)\n",
    "      self.decoder = Decoder(d_model, n_decoders, Config.FF_DROPOUT)\n",
    "\n",
    "      self.generator = Generator(d_model, tgt_vocab_size)\n",
    "\n",
    "      calc_total_params(self.src_embed, \"Source Embedding\")\n",
    "      calc_total_params(self.tgt_embed, \"Target Embedding\")\n",
    "      calc_total_params(self.encoder, \"Encoder\")\n",
    "      calc_total_params(self.decoder, \"Decoder\")\n",
    "      calc_total_params(self.generator, \"Generator\")\n",
    "      calc_total_params(self, \"Transfomer\")\n",
    "\n",
    "   def forward(self, src, tgt):\n",
    "      # Generate source padding mask\n",
    "      src_padding_mask = generate_padding_mask(src, VI_PAD_ID)\n",
    "\n",
    "      src_emb = self.src_embed(src)\n",
    "      # Pass source padding mask to encoder\n",
    "      enc_o = self.encoder(src_emb, src_padding_mask=src_padding_mask)\n",
    "\n",
    "      # Generate target mask for the decoder (look-ahead mask)\n",
    "      tgt_seq_len = tgt.shape[1]\n",
    "      tgt_mask = generate_subsequence_mask(tgt_seq_len).to(device)\n",
    "      # Generate target padding mask\n",
    "      tgt_padding_mask = generate_padding_mask(tgt, EN_PAD_ID)\n",
    "\n",
    "      tgt_emb = self.tgt_embed(tgt)\n",
    "      # Pass target look-ahead mask, target padding mask, and encoder output padding mask to decoder\n",
    "      dec_o = self.decoder(tgt_emb, enc_o, target_mask=tgt_mask, target_padding_mask=tgt_padding_mask, memory_padding_mask=src_padding_mask)\n",
    "      return self.generator(dec_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ad92e5",
   "metadata": {
    "id": "I5maUfjhmkZ-",
    "papermill": {
     "duration": 0.007791,
     "end_time": "2025-12-15T10:25:37.313681",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.305890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "510b7fce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:37.330742Z",
     "iopub.status.busy": "2025-12-15T10:25:37.330533Z",
     "iopub.status.idle": "2025-12-15T10:25:37.336192Z",
     "shell.execute_reply": "2025-12-15T10:25:37.335673Z"
    },
    "papermill": {
     "duration": 0.015306,
     "end_time": "2025-12-15T10:25:37.337177",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.321871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"# Label Smoothing\"\"\"\n",
    "\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"\"\"\n",
    "    Label Smoothing for NMT.\n",
    "    \n",
    "    Instead of hard targets [0, 0, 1, 0, 0] (one-hot), we smooth:\n",
    "    - True class: confidence (e.g., 0.9 instead of 1.0)\n",
    "    - Other classes: smoothing / (vocab_size - 1)\n",
    "    - Padding token: always 0\n",
    "    \n",
    "    Prevents overconfidence and improves generalization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size: int, padding_idx: int, smoothing: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction='batchmean')  # Changed from 'sum' to 'batchmean'\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "    def forward(self, logits: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            logits: Model outputs (before softmax), shape [batch * seq_len, vocab_size]\n",
    "            target: Target token IDs, shape [batch * seq_len]\n",
    "        \n",
    "        Returns:\n",
    "            Smoothed KL divergence loss\n",
    "        \"\"\"\n",
    "        assert logits.size(1) == self.vocab_size\n",
    "        \n",
    "        # Create smoothed distribution\n",
    "        true_dist = logits.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.vocab_size - 2))  # -2 for true class and padding\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        \n",
    "        # Set padding positions to 0\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        \n",
    "        # KL divergence between log_softmax(logits) and smoothed distribution\n",
    "        return self.criterion(F.log_softmax(logits, dim=1), true_dist.clone().detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6ae4864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:37.354148Z",
     "iopub.status.busy": "2025-12-15T10:25:37.353723Z",
     "iopub.status.idle": "2025-12-15T10:25:37.360199Z",
     "shell.execute_reply": "2025-12-15T10:25:37.359672Z"
    },
    "id": "AiyZWXzxBzxJ",
    "papermill": {
     "duration": 0.016164,
     "end_time": "2025-12-15T10:25:37.361216",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.345052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, criterion, train_loader, val_loader, device, epochs):\n",
    "  model = model.to(device)\n",
    "\n",
    "  train_losses_history = []\n",
    "  val_losses_history = []\n",
    "  pps_history = []\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for vi, en_in, en_tar in tqdm(train_loader):\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      vi = vi.to(device)\n",
    "      en_in = en_in.to(device)\n",
    "      en_tar = en_tar.to(device)\n",
    "      output = model(vi, en_in)\n",
    "      loss = criterion(output.reshape(-1, output.shape[-1]), en_tar.reshape(-1)) # (batch_size * seq_len, tgt_vocab_size)  (batch_size * seq_len)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      total_train_loss += loss.item()\n",
    "\n",
    "      scheduler.step()\n",
    "\n",
    "    total_val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for vi, en_in, en_tar in tqdm(val_loader):\n",
    "        vi = vi.to(device)\n",
    "        en_in = en_in.to(device)\n",
    "        en_tar = en_tar.to(device)\n",
    "\n",
    "        output = model(vi, en_in)\n",
    "        val_loss = criterion(output.reshape(-1, output.shape[-1]), en_tar.reshape(-1))\n",
    "\n",
    "        total_val_loss += val_loss.item()\n",
    "\n",
    "    total_train_loss /= len(train_loader)\n",
    "    total_val_loss /= len(val_loader)\n",
    "      \n",
    "    # Prevent overflow when calculating perplexity\n",
    "    try:\n",
    "        pp = math.exp(total_val_loss)\n",
    "    except OverflowError:\n",
    "        pp = float('inf')\n",
    "\n",
    "\n",
    "    train_losses_history.append(total_train_loss)\n",
    "    val_losses_history.append(total_val_loss)\n",
    "    pps_history.append(pp)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{epochs} | Train Loss: {total_train_loss:.4f} | Val Loss: {total_val_loss:.4f} | Perplexity: {pp:.4f}\")\n",
    "\n",
    "  return train_losses_history, val_losses_history, pps_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7537baf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:37.379255Z",
     "iopub.status.busy": "2025-12-15T10:25:37.378610Z",
     "iopub.status.idle": "2025-12-15T10:25:37.383216Z",
     "shell.execute_reply": "2025-12-15T10:25:37.382688Z"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1765371396606,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "-C3jJKK4gte0",
    "outputId": "963ab211-4b12-4b9a-b3ae-286851884a50",
    "papermill": {
     "duration": 0.01499,
     "end_time": "2025-12-15T10:25:37.384242",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.369252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([51])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1bb8d69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:37.401675Z",
     "iopub.status.busy": "2025-12-15T10:25:37.401469Z",
     "iopub.status.idle": "2025-12-15T10:25:37.672840Z",
     "shell.execute_reply": "2025-12-15T10:25:37.671867Z"
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1765371397001,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "j87PurZcbWZI",
    "outputId": "eaeb71ef-17fe-4aab-b769-ab7d4b0fd6ec",
    "papermill": {
     "duration": 0.281478,
     "end_time": "2025-12-15T10:25:37.674213",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.392735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Embedding initialized with 1,656,064 params\n",
      "Target Embedding initialized with 4,024,832 params\n",
      "Encoder initialized with 2,855,168 params\n",
      "Decoder initialized with 3,348,992 params\n",
      "Generator initialized with 4,040,554 params\n",
      "Transfomer initialized with 15,925,610 params\n"
     ]
    }
   ],
   "source": [
    "# src_embed = Embedding(Config.D_MODEL, VI_VOCAB_LEN)\n",
    "# tgt_embed = Embedding(Config.D_MODEL, EN_VOCAB_LEN)\n",
    "# pe = PositionEmbedding(Config.D_MODEL, max(VI_VOCAB_LEN, EN_VOCAB_LEN), Config.PE_DROP_OUT)\n",
    "\n",
    "# model = Transformer(\n",
    "#    d_model=Config.D_MODEL,\n",
    "#    tgt_vocab_size=EN_VOCAB_LEN,\n",
    "#    src_embed=nn.Sequential(src_embed, copy.deepcopy(pe)),\n",
    "#    tgt_embed=nn.Sequential(tgt_embed, copy.deepcopy(pe)),\n",
    "#    n_encoders=Config.N_ENCODERS,\n",
    "#    n_decoders=Config.N_DECODERS\n",
    "# )\n",
    "src_embed = nn.Sequential(\n",
    "   Embedding(Config.D_MODEL, VI_VOCAB_LEN),\n",
    "   PositionEmbedding(\n",
    "      Config.D_MODEL,\n",
    "      max(VI_VOCAB_LEN,\n",
    "          EN_VOCAB_LEN),\n",
    "      Config.PE_DROP_OUT)\n",
    "   )\n",
    "tgt_embed = nn.Sequential(\n",
    "   Embedding(Config.D_MODEL, EN_VOCAB_LEN),\n",
    "   PositionEmbedding(\n",
    "      Config.D_MODEL,\n",
    "      max(VI_VOCAB_LEN,\n",
    "          EN_VOCAB_LEN),\n",
    "      Config.PE_DROP_OUT)\n",
    "   )\n",
    "\n",
    "model = Transformer(\n",
    "    d_model=Config.D_MODEL,\n",
    "    tgt_vocab_size=EN_VOCAB_LEN,\n",
    "    src_embed=src_embed,\n",
    "    tgt_embed=tgt_embed,\n",
    "    n_encoders=Config.N_ENCODERS,\n",
    "    n_decoders=Config.N_DECODERS\n",
    ")\n",
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "model.apply(initialize_weights);\n",
    "\n",
    "# model.load_state_dict(torch.load(\"Transformer_5_epoch.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b2ba4ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:37.693739Z",
     "iopub.status.busy": "2025-12-15T10:25:37.693462Z",
     "iopub.status.idle": "2025-12-15T10:25:37.696574Z",
     "shell.execute_reply": "2025-12-15T10:25:37.696034Z"
    },
    "id": "BszibKFcd3Xq",
    "papermill": {
     "duration": 0.014223,
     "end_time": "2025-12-15T10:25:37.697708",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.683485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af3d9327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:37.716051Z",
     "iopub.status.busy": "2025-12-15T10:25:37.715847Z",
     "iopub.status.idle": "2025-12-15T10:25:41.757977Z",
     "shell.execute_reply": "2025-12-15T10:25:41.757397Z"
    },
    "id": "oAQMHb1TbLtu",
    "papermill": {
     "duration": 4.053027,
     "end_time": "2025-12-15T10:25:41.759307",
     "exception": false,
     "start_time": "2025-12-15T10:25:37.706280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=epochs\n",
    ")\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index=EN_PAD_ID)\n",
    "criterion = LabelSmoothing(vocab_size=EN_VOCAB_LEN, padding_idx=EN_PAD_ID, smoothing=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8cf012b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:25:41.777597Z",
     "iopub.status.busy": "2025-12-15T10:25:41.777270Z",
     "iopub.status.idle": "2025-12-15T11:10:46.552690Z",
     "shell.execute_reply": "2025-12-15T11:10:46.551785Z"
    },
    "executionInfo": {
     "elapsed": 3370755,
     "status": "ok",
     "timestamp": 1765374767755,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "AELRCqd5cbag",
    "outputId": "58028e06-dcee-438c-f927-1baf655f9a84",
    "papermill": {
     "duration": 2704.785648,
     "end_time": "2025-12-15T11:10:46.553830",
     "exception": false,
     "start_time": "2025-12-15T10:25:41.768182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8260/8260 [04:30<00:00, 30.57it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 89.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 | Train Loss: 1.7937 | Val Loss: 1.4549 | Perplexity: 4.2841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8260/8260 [04:29<00:00, 30.63it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 88.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10 | Train Loss: 1.2799 | Val Loss: 1.1567 | Perplexity: 3.1794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8260/8260 [04:30<00:00, 30.59it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 88.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10 | Train Loss: 1.0851 | Val Loss: 1.0483 | Perplexity: 2.8528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8260/8260 [04:29<00:00, 30.65it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 88.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10 | Train Loss: 0.9645 | Val Loss: 0.9672 | Perplexity: 2.6305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8260/8260 [04:29<00:00, 30.60it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 88.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10 | Train Loss: 0.8758 | Val Loss: 0.9220 | Perplexity: 2.5143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8260/8260 [04:29<00:00, 30.67it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 89.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10 | Train Loss: 0.8069 | Val Loss: 0.8908 | Perplexity: 2.4371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8260/8260 [04:29<00:00, 30.61it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 90.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10 | Train Loss: 0.7416 | Val Loss: 0.8623 | Perplexity: 2.3687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8260/8260 [04:29<00:00, 30.64it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 91.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10 | Train Loss: 0.6818 | Val Loss: 0.8496 | Perplexity: 2.3387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8260/8260 [04:31<00:00, 30.47it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 89.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10 | Train Loss: 0.6347 | Val Loss: 0.8421 | Perplexity: 2.3212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8260/8260 [04:29<00:00, 30.60it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 88.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10 | Train Loss: 0.6071 | Val Loss: 0.8437 | Perplexity: 2.3250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tz = timezone(\"Etc/GMT-7\")\n",
    "now = datetime.datetime.now(tz).strftime(\"%d-%m-%Y_%Hh%Mm\")\n",
    "train_losses, val_losses, pps = train(model, optimizer, scheduler, criterion, train_loader, val_loader, device, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "140689ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T11:10:48.393909Z",
     "iopub.status.busy": "2025-12-15T11:10:48.393589Z",
     "iopub.status.idle": "2025-12-15T11:10:48.716268Z",
     "shell.execute_reply": "2025-12-15T11:10:48.715597Z"
    },
    "executionInfo": {
     "elapsed": 1947,
     "status": "error",
     "timestamp": 1765375897584,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "uwKtt2P9IS7L",
    "outputId": "1c152e51-b764-4bbf-cd1b-1698d0c35ad7",
    "papermill": {
     "duration": 1.253082,
     "end_time": "2025-12-15T11:10:48.717634",
     "exception": false,
     "start_time": "2025-12-15T11:10:47.464552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model\": model.state_dict(),\n",
    "    \"optimizer\": optimizer.state_dict(),\n",
    "    \"epoch\": epochs,\n",
    "}, f\"checkpoint-{now}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b499712e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T11:10:50.475794Z",
     "iopub.status.busy": "2025-12-15T11:10:50.474975Z",
     "iopub.status.idle": "2025-12-15T11:10:50.478402Z",
     "shell.execute_reply": "2025-12-15T11:10:50.477891Z"
    },
    "executionInfo": {
     "elapsed": 698,
     "status": "ok",
     "timestamp": 1765377361281,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "VyIuh1Fymniu",
    "outputId": "b1594598-7333-41c1-fb89-11ef5bbc7675",
    "papermill": {
     "duration": 0.920521,
     "end_time": "2025-12-15T11:10:50.479416",
     "exception": false,
     "start_time": "2025-12-15T11:10:49.558895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(\"/content/drive/MyDrive/NLP/models/checkpoint-10-12-2025_19h56m.pth\", map_location=\"cpu\")\n",
    "\n",
    "# model.load_state_dict(checkpoint[\"model\"])\n",
    "# optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "# epoch = checkpoint[\"epoch\"]\n",
    "# model.generator.proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6e47447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T11:10:52.109493Z",
     "iopub.status.busy": "2025-12-15T11:10:52.109225Z",
     "iopub.status.idle": "2025-12-15T11:10:52.302511Z",
     "shell.execute_reply": "2025-12-15T11:10:52.301819Z"
    },
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1765374768542,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "5Fwn9P_znQoq",
    "outputId": "b0af9610-b7d2-49ac-b403-c0c4f1fc68f9",
    "papermill": {
     "duration": 1.007622,
     "end_time": "2025-12-15T11:10:52.303753",
     "exception": false,
     "start_time": "2025-12-15T11:10:51.296131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Val Loss\")\n",
    "plt.plot(pps, label=\"Perplexity\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a16743d",
   "metadata": {
    "id": "7TYAe7Jr3OSH",
    "papermill": {
     "duration": 0.921197,
     "end_time": "2025-12-15T11:10:54.137740",
     "exception": false,
     "start_time": "2025-12-15T11:10:53.216543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2532e384",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T11:10:55.772410Z",
     "iopub.status.busy": "2025-12-15T11:10:55.772142Z",
     "iopub.status.idle": "2025-12-15T11:10:55.776211Z",
     "shell.execute_reply": "2025-12-15T11:10:55.775632Z"
    },
    "id": "nSfp2cptLBCP",
    "papermill": {
     "duration": 0.824529,
     "end_time": "2025-12-15T11:10:55.777215",
     "exception": false,
     "start_time": "2025-12-15T11:10:54.952686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ids2sentence(ids, vocab_map) -> str:\n",
    "  tokens = []\n",
    "  for i in ids:\n",
    "    if i not in [EN_SOS_ID, EN_EOS_ID, EN_PAD_ID]:\n",
    "      tokens.append(vocab_map[str(i)])\n",
    "  return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f97a686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T11:10:57.601604Z",
     "iopub.status.busy": "2025-12-15T11:10:57.601075Z",
     "iopub.status.idle": "2025-12-15T11:12:07.426970Z",
     "shell.execute_reply": "2025-12-15T11:12:07.426060Z"
    },
    "id": "Btrnf6SbMTYG",
    "papermill": {
     "duration": 71.198164,
     "end_time": "2025-12-15T11:12:07.884999",
     "exception": false,
     "start_time": "2025-12-15T11:10:56.686835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m123.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b4a9e64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T11:12:09.831861Z",
     "iopub.status.busy": "2025-12-15T11:12:09.831529Z",
     "iopub.status.idle": "2025-12-15T11:12:09.836852Z",
     "shell.execute_reply": "2025-12-15T11:12:09.836053Z"
    },
    "id": "07p9q1H5fCfA",
    "papermill": {
     "duration": 1.042195,
     "end_time": "2025-12-15T11:12:09.838240",
     "exception": false,
     "start_time": "2025-12-15T11:12:08.796045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/NLP/Transformer_5_epoch.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "184875f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T11:12:11.759460Z",
     "iopub.status.busy": "2025-12-15T11:12:11.759161Z",
     "iopub.status.idle": "2025-12-15T11:12:11.763281Z",
     "shell.execute_reply": "2025-12-15T11:12:11.762717Z"
    },
    "id": "BCl-d6DCj3FB",
    "papermill": {
     "duration": 0.852357,
     "end_time": "2025-12-15T11:12:11.764376",
     "exception": false,
     "start_time": "2025-12-15T11:12:10.912019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=config_dict['batch_size'], collate_fn=collate_fn, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9888c438",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T11:12:13.556526Z",
     "iopub.status.busy": "2025-12-15T11:12:13.556210Z",
     "iopub.status.idle": "2025-12-15T11:12:13.561120Z",
     "shell.execute_reply": "2025-12-15T11:12:13.560487Z"
    },
    "id": "A0LF2tOf-jB1",
    "papermill": {
     "duration": 0.858906,
     "end_time": "2025-12-15T11:12:13.562512",
     "exception": false,
     "start_time": "2025-12-15T11:12:12.703606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_preds_target(preds, target):\n",
    "  processed_dict = {}\n",
    "\n",
    "  for pred, tar in zip(preds, target):\n",
    "    if pred not in processed_dict:\n",
    "      processed_dict[pred] = [tar]\n",
    "    else:\n",
    "      processed_dict[pred].append(tar)\n",
    "\n",
    "  return list(processed_dict.keys()), list(processed_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9861611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T11:12:15.416451Z",
     "iopub.status.busy": "2025-12-15T11:12:15.416185Z",
     "iopub.status.idle": "2025-12-15T11:12:32.212313Z",
     "shell.execute_reply": "2025-12-15T11:12:32.211402Z"
    },
    "executionInfo": {
     "elapsed": 14812,
     "status": "ok",
     "timestamp": 1765377429397,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "HLxHapwxx4N-",
    "outputId": "8bbaa54f-5659-4e87-97b8-ae8ead62bc5f",
    "papermill": {
     "duration": 17.769415,
     "end_time": "2025-12-15T11:12:32.213463",
     "exception": false,
     "start_time": "2025-12-15T11:12:14.444048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:10<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Origin: họ bán các chứng chỉ bảo mật </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Pred: they sell their security evidence . \n",
      "Target: ['they sell certificates .']\n",
      " - Origin: ở đất nước của chúng ta , tại những bang miền nam lâu đời người ta vẫn thực thi án tử hình bạn có khả năng bị kết án tử hình cao gấp 11 lần nếu nạn nhân là người da trắng so với nạn nhân là người da đen và gấp 22 lần nếu bị đơn là người da đen còn nạn nhân là người da trắng chính những tiểu bang này đã chôn biết bao thi thể của người bị xử tử </s> \n",
      "Pred: in our country , in the south states , who live in the early stages , they can still be able to get a <unk> death sentence , 11 times as the white , if the victim is black and 22 times as black or six times as the black and the black <unk> , these states have known as the person . \n",
      "Target: [\"and yet , in this country , in the states of the old south , we execute people -- where you 're 11 times more likely to get the death penalty if the victim is white than if the victim is black , 22 times more likely to get it if the <unk> is black and the victim is white -- in the very states where there are buried in the ground the bodies of people who were <unk> .\"]\n",
      " - Origin: và cuối cùng tôi quyết định tôi sẽ đến toà án và nhận vụ án khó khăn này . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Pred: and i finally decided i was going to go to this difficult building . \n",
      "Target: [\"and i finally decided , oh gosh , i 've got to go to the court and do this crazy case .\"]\n",
      " - Origin: tôi bước vào xe , trong lòng cảm thấy rất rất choáng ngợp . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Pred: i walked into my car , and i felt very overwhelmed . \n",
      "Target: ['and i got into my car and i was feeling really overwhelmed -- overwhelmed .']\n",
      " - Origin: bởi vì tôi nghĩ rằng cách duy nhất để hiểu được điều này là thực sự đặt mình vào trong quá khứ và dành một cái nhìn lâu dài vào mọi vật . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "Pred: because i think the only way to understand this is to actually put myself into the past and spend a long-term look at things . \n",
      "Target: ['because i think the only way to understand this is to really step back and take a long time scale look at things .']\n",
      "BLEU Score: 0.23112918436527252\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.text import BLEUScore\n",
    "\n",
    "def test(model, test_loader, n_gram=4, max_generated_token_len=94):\n",
    "  bleu_metric = BLEUScore(n_gram=n_gram)\n",
    "\n",
    "  model = model.to(device)\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    src_embed = model.src_embed\n",
    "    tgt_embed = model.tgt_embed\n",
    "    encoder = model.encoder\n",
    "    decoder = model.decoder\n",
    "    generator = model.generator\n",
    "\n",
    "    all_source = []\n",
    "    all_preds = []\n",
    "    all_target = []\n",
    "    for vi, _, en_out in tqdm(test_loader):\n",
    "      # Generate source padding mask for the encoder\n",
    "      src_padding_mask = generate_padding_mask(vi, VI_PAD_ID)\n",
    "\n",
    "      enc_o = encoder(src_embed(vi), src_padding_mask=src_padding_mask)\n",
    "      batch_size = vi.shape[0]\n",
    "      decoder_input = torch.full((batch_size, 1), EN_SOS_ID, device=device)\n",
    "\n",
    "      batch_outputs = [[] for _ in range(batch_size)]\n",
    "      is_finished = [False] * batch_size  # track EOS\n",
    "      for _ in range(max_generated_token_len):\n",
    "        # Pass all relevant masks to the decoder\n",
    "        dec_o = decoder(tgt_embed(decoder_input), enc_o, memory_padding_mask=src_padding_mask)\n",
    "        output = generator(dec_o)  # (batch_sz, seq_len, vocab_sz)\n",
    "\n",
    "        next_token_id = torch.argmax(output[:, -1, :], dim=-1)  # (batch_sz)\n",
    "        next_token = next_token_id.unsqueeze(1)\n",
    "\n",
    "        decoder_input = torch.cat([decoder_input, next_token], dim=-1)\n",
    "\n",
    "        last_tokens = next_token_id.tolist()\n",
    "        for i in range(batch_size):\n",
    "          if not is_finished[i]:\n",
    "            last_token = last_tokens[i]\n",
    "            if last_token == EN_EOS_ID:\n",
    "              is_finished[i] = True\n",
    "            else:\n",
    "              batch_outputs[i].append(last_token)\n",
    "\n",
    "        # Stop early if all sentences finished\n",
    "        if all(is_finished):\n",
    "          break\n",
    "\n",
    "      all_preds.extend(batch_outputs)\n",
    "      all_target.extend(en_out.tolist())\n",
    "      all_source.extend(vi.tolist())\n",
    "      # check 1 batch\n",
    "      # break\n",
    "    sources = [ids2sentence(vi, vi_id2token) for vi in all_source]\n",
    "    preds = [ids2sentence(pred, en_id2token) for pred in all_preds]\n",
    "    target = [ids2sentence(tar, en_id2token) for tar in all_target]\n",
    "\n",
    "    preds, target = process_preds_target(preds, target)\n",
    "    for i in range(5):\n",
    "      print(f\" - Origin: {sources[i]} \\nPred: {preds[i]} \\nTarget: {target[i]}\")\n",
    "\n",
    "    score = bleu_metric(preds, target)\n",
    "    print(f\"BLEU Score: {score.item()}\")\n",
    "\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be8f9be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T11:12:34.010922Z",
     "iopub.status.busy": "2025-12-15T11:12:34.010411Z",
     "iopub.status.idle": "2025-12-15T11:12:34.015203Z",
     "shell.execute_reply": "2025-12-15T11:12:34.014662Z"
    },
    "id": "lMchiTljmtlV",
    "papermill": {
     "duration": 0.84594,
     "end_time": "2025-12-15T11:12:34.016389",
     "exception": false,
     "start_time": "2025-12-15T11:12:33.170449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PredDataset(Dataset):\n",
    "  def __init__(self, vi):\n",
    "    self.vi = [tokens + [VI_EOS_ID] for tokens in vi]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.vi)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return torch.tensor(self.vi[idx])\n",
    "\n",
    "def pred_collate_fn(batch):\n",
    "  vi_ts = pad_sequence(batch, batch_first=True, padding_value=VI_PAD_ID)\n",
    "  return vi_ts.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c983064f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T11:12:37.620038Z",
     "iopub.status.busy": "2025-12-15T11:12:37.619607Z",
     "iopub.status.idle": "2025-12-15T11:12:37.629108Z",
     "shell.execute_reply": "2025-12-15T11:12:37.628540Z"
    },
    "id": "a6216470",
    "papermill": {
     "duration": 0.849314,
     "end_time": "2025-12-15T11:12:37.630148",
     "exception": false,
     "start_time": "2025-12-15T11:12:36.780834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, sentences, max_generated_token_len=5, beam_size=5):\n",
    "  vi = [[vi_token2id.get(token, VI_UNK_ID) for token in sentence.split()] for sentence in sentences]\n",
    "\n",
    "  model = model.to(device)\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    src_embed = model.src_embed\n",
    "    tgt_embed = model.tgt_embed\n",
    "    encoder = model.encoder\n",
    "    decoder = model.decoder\n",
    "    generator = model.generator\n",
    "\n",
    "    all_best_preds = [] # List to store the best prediction for each sentence\n",
    "    all_sources_in_batch_order = [] # To store original source sentences in batch order\n",
    "\n",
    "    pred_dataset = PredDataset(vi)\n",
    "    loader = DataLoader(pred_dataset, batch_size=config_dict['batch_size'], collate_fn=pred_collate_fn)\n",
    "\n",
    "    sentence_idx = 0\n",
    "    for vi_batch in tqdm(loader):\n",
    "      src_padding_mask = generate_padding_mask(vi_batch, VI_PAD_ID)\n",
    "      enc_o = encoder(src_embed(vi_batch), src_padding_mask=src_padding_mask)\n",
    "\n",
    "      batch_size = vi_batch.shape[0]\n",
    "\n",
    "      for i in range(batch_size):\n",
    "        # Store the original source sentence for this item in the batch\n",
    "        all_sources_in_batch_order.append(sentences[sentence_idx])\n",
    "\n",
    "        encoder_out = enc_o[i].unsqueeze(0)  # (1, seq_len, d_model)\n",
    "        enc_pad_mask_i = src_padding_mask[i].unsqueeze(0)\n",
    "\n",
    "        beams = [(torch.tensor([EN_SOS_ID], device=device), 0.0, False)] # (sequence, score, finished)\n",
    "\n",
    "        for _ in range(max_generated_token_len):\n",
    "          candidates = []\n",
    "\n",
    "          for seq, score, finished in beams:\n",
    "            if finished:\n",
    "              candidates.append((seq, score, True))\n",
    "              continue\n",
    "\n",
    "            seq_input = seq.unsqueeze(0)  # (1, seq_len)\n",
    "            # Generate target mask for the decoder (look-ahead mask)\n",
    "            tgt_seq_len = seq_input.shape[1]\n",
    "            tgt_mask = generate_subsequence_mask(tgt_seq_len).to(device)\n",
    "\n",
    "            # Generate target padding mask (not needed here as beam sequences don't have pads until final processing)\n",
    "            # For simplicity, we can create a dummy one or ensure it doesn't interfere\n",
    "\n",
    "            dec_out = decoder(tgt_embed(seq_input), encoder_out, target_mask=tgt_mask, memory_padding_mask=enc_pad_mask_i)\n",
    "            logits = generator(dec_out)\n",
    "\n",
    "            # last token\n",
    "            log_probs = torch.log_softmax(logits[:, -1, :], dim=-1).squeeze(0)  # (vocab_len)\n",
    "\n",
    "            # topk\n",
    "            topk_log_probs, topk_ids = torch.topk(log_probs, beam_size)\n",
    "            for log_p, token_id in zip(topk_log_probs, topk_ids):\n",
    "              new_seq = torch.cat([seq, torch.tensor([token_id], device=device)])\n",
    "              new_score = score + log_p.item()\n",
    "              new_finished = token_id == EN_EOS_ID\n",
    "              candidates.append((new_seq, new_score, new_finished))\n",
    "\n",
    "          # sorted by score, topk\n",
    "          candidates = sorted(candidates, key=lambda x: x[1]/len(x[0]), reverse=True) # Normalize score by length\n",
    "          beams = candidates[:beam_size]\n",
    "\n",
    "          # all finished = True\n",
    "          if all(f for _, _, f in beams):\n",
    "              break\n",
    "\n",
    "        # After beam search for one sentence, select the best prediction\n",
    "        best_seq_tokens = beams[0][0].cpu().tolist()\n",
    "        best_pred_sentence = ids2sentence(best_seq_tokens, en_id2token)\n",
    "        all_best_preds.append(best_pred_sentence)\n",
    "        sentence_idx += 1\n",
    "\n",
    "    return all_sources_in_batch_order, all_best_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6492f1b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T11:12:41.229191Z",
     "iopub.status.busy": "2025-12-15T11:12:41.228678Z",
     "iopub.status.idle": "2025-12-15T11:18:39.357919Z",
     "shell.execute_reply": "2025-12-15T11:18:39.356963Z"
    },
    "executionInfo": {
     "elapsed": 435016,
     "status": "ok",
     "timestamp": 1765378696561,
     "user": {
      "displayName": "Phong Trần",
      "userId": "08913498727775667910"
     },
     "user_tz": -420
    },
    "id": "56724f16",
    "outputId": "bc598bf6-276a-4b59-b473-34a99d82e6e2",
    "papermill": {
     "duration": 358.975261,
     "end_time": "2025-12-15T11:18:39.359229",
     "exception": false,
     "start_time": "2025-12-15T11:12:40.383968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [05:56<00:00,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.2580\n",
      "\n",
      "--- Sample Translations ---\n",
      "Original (vi): họ bán các chứng chỉ bảo mật\n",
      "Predicted (en): they sell their security evidence .\n",
      "Target (en): they sell certificates .\n",
      "\n",
      "\n",
      "Original (vi): ở đất nước của chúng ta , tại những bang miền nam lâu đời người ta vẫn thực thi án tử hình bạn có khả năng bị kết án tử hình cao gấp 11 lần nếu nạn nhân là người da trắng so với nạn nhân là người da đen và gấp 22 lần nếu bị đơn là người da đen còn nạn nhân là người da trắng chính những tiểu bang này đã chôn biết bao thi thể của người bị xử tử\n",
      "Predicted (en): in our country , in the secular states , in the secular states , people still do the death sentence , you have the ability to get <unk> death twice as if the victim is black and 22 times as seven times as black or six times as the black and the black person is the white of those states who know how to behave .\n",
      "Target (en): and yet , in this country , in the states of the old south , we execute people -- where you 're 11 times more likely to get the death penalty if the victim is white than if the victim is black , 22 times more likely to get it if the <unk> is black and the victim is white -- in the very states where there are buried in the ground the bodies of people who were <unk> .\n",
      "\n",
      "\n",
      "Original (vi): và cuối cùng tôi quyết định tôi sẽ đến toà án và nhận vụ án khó khăn này .\n",
      "Predicted (en): and i finally decided i was going to go to this building and take this difficult case .\n",
      "Target (en): and i finally decided , oh gosh , i 've got to go to the court and do this crazy case .\n",
      "\n",
      "\n",
      "Original (vi): tôi bước vào xe , trong lòng cảm thấy rất rất choáng ngợp .\n",
      "Predicted (en): i walked into my car , and i felt very overwhelmed .\n",
      "Target (en): and i got into my car and i was feeling really overwhelmed -- overwhelmed .\n",
      "\n",
      "\n",
      "Original (vi): bởi vì tôi nghĩ rằng cách duy nhất để hiểu được điều này là thực sự đặt mình vào trong quá khứ và dành một cái nhìn lâu dài vào mọi vật .\n",
      "Predicted (en): because i think the only way to understand this is to actually put myself into the past and spend a long-term look at everything .\n",
      "Target (en): because i think the only way to understand this is to really step back and take a long time scale look at things .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.text import BLEUScore\n",
    "\n",
    "# Run prediction on the entire test set\n",
    "source_sentences, predicted_sentences = predict(model, test_df['vi'].tolist(), max_generated_token_len=94, beam_size=5)\n",
    "\n",
    "# Prepare target sentences from test_df['en_token']\n",
    "target_token_ids = test_df['en_token'].tolist()\n",
    "target_sentences = []\n",
    "for tokens in target_token_ids:\n",
    "    # ids2sentence removes SOS/EOS/PAD, BLEUScore expects reference sentences as lists of strings.\n",
    "    # So, we convert each target sentence to a list containing one string, as required by torchmetrics.\n",
    "    target_sentences.append([ids2sentence(tokens, en_id2token)])\n",
    "\n",
    "# Initialize BLEU metric\n",
    "bleu_metric = BLEUScore(n_gram=4)\n",
    "\n",
    "# Calculate BLEU score\n",
    "score = bleu_metric(predicted_sentences, target_sentences)\n",
    "\n",
    "print(f\"BLEU Score: {score.item():.4f}\")\n",
    "\n",
    "print(\"\\n--- Sample Translations ---\")\n",
    "for i in range(5):\n",
    "    print(f\"Original (vi): {source_sentences[i]}\")\n",
    "    print(f\"Predicted (en): {predicted_sentences[i]}\")\n",
    "    print(f\"Target (en): {target_sentences[i][0]}\") # target_sentences is list of lists, so access [0]\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31a08ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Python SDK\n",
    "import google.generativeai as genai\n",
    "# Used to securely store your API key\n",
    "from google.colab import userdata\n",
    "\n",
    "# Retrieve the API key from Colab secrets\n",
    "genai.configure(api_key='GEMINI_KEY')\n",
    "\n",
    "# Initialize the Generative Model\n",
    "gemini_model = genai.GenerativeModel('gemini-2.5-flash-lite') # Using a capable model for evaluation\n",
    "print(\"Gemini API configured successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe2b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "def create_llm_judge_prompt(source, predicted, reference):\n",
    "    return f\"\"\"You are an expert in evaluating machine translations. You will be provided with a Source sentence, a Machine Translation (Predicted), and a Human Reference Translation. \n",
    "    \n",
    "Your task is to rate the quality of the Machine Translation on a scale of 1 to 10.\n",
    "\n",
    "Scale Definition:\n",
    "1: Nonsense - No meaning is conveyed; hallucination or completely wrong.\n",
    "2: Very Poor - Severe inaccuracies; barely understandable.\n",
    "3: Poor - Conveying some isolated meaning, but grammatically broken or very confusing.\n",
    "4: Below Average - The gist is there, but with critical errors in accuracy or grammar.\n",
    "5: Average - Understandable, but awkward phrasing or noticeable errors.\n",
    "6: Above Average - Mostly correct meaning, but lacks fluency or has minor grammatical slips.\n",
    "7: Good - Accurate and readable, but may not sound completely native.\n",
    "8: Very Good - Fluent and accurate; only very minor stylistic imperfections.\n",
    "9: Excellent - Near-perfect translation, preserving nuance and tone.\n",
    "10: Perfect - Indistinguishable from a professional human translator.\n",
    "\n",
    "Please provide your rating as a single integer (1-10) at the end of your response.\n",
    "Do not include any other text besides your justification and the final score.\n",
    "\n",
    "Source: {source}\n",
    "Predicted: {predicted}\n",
    "Reference: {reference}\n",
    "Rating:\n",
    "\"\"\"\n",
    "\n",
    "def evaluate_with_gemini_batch(sources, predicted_sentences, target_sentences, model, batch_size=10):\n",
    "    eval_scores = []\n",
    "    \n",
    "    # Iterate through data in batches\n",
    "    for i in tqdm(range(0, len(sources), batch_size), desc=\"Evaluating with Gemini\"):\n",
    "        sleep(1)\n",
    "        batch_sources = sources[i:i + batch_size]\n",
    "        batch_predicted = predicted_sentences[i:i + batch_size]\n",
    "        batch_targets = target_sentences[i:i + batch_size]\n",
    "\n",
    "        prompts = [\n",
    "            create_llm_judge_prompt(src, pred, tar[0]) \n",
    "            for src, pred, tar in zip(batch_sources, batch_predicted, batch_targets)\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            # Note: Ensure your model object supports list input for 'prompts'. \n",
    "            # If using standard Google GenAI SDK, you might need to loop individually \n",
    "            # or use specific batching API methods.\n",
    "            responses = model.generate_content(prompts, generation_config={'temperature': 0})\n",
    "            \n",
    "            # Handle case where response might be a single object vs list based on SDK version\n",
    "            if not isinstance(responses, list) and hasattr(responses, 'text'):\n",
    "                 # Fallback if API returns single response for single prompt\n",
    "                 responses = [responses] \n",
    "\n",
    "            for res in responses:\n",
    "                try:\n",
    "                    text = res.text.strip()\n",
    "                    # REGEX UPDATE: Looks for 10 or 1-9\n",
    "                    matches = re.findall(r'\\b(10|[1-9])\\b', text)\n",
    "                    \n",
    "                    if matches:\n",
    "                        # Get the last number found in the response\n",
    "                        eval_scores.append(int(matches[-1]))\n",
    "                    else:\n",
    "                        eval_scores.append(None)\n",
    "                except ValueError:\n",
    "                    # Handle cases where safety filters block the text\n",
    "                    eval_scores.append(None)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error during batch generation: {e}\")\n",
    "            eval_scores.extend([None] * len(batch_sources))\n",
    "\n",
    "    return eval_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a02c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'gemini_model' in locals():\n",
    "    sample_sources = source_sentences\n",
    "    sample_predicted = predicted_sentences\n",
    "    sample_targets = target_sentences\n",
    "\n",
    "    gemini_scores = evaluate_with_gemini_batch(\n",
    "        sample_sources,\n",
    "        sample_predicted,\n",
    "        sample_targets,\n",
    "        gemini_model,\n",
    "        batch_size=10\n",
    "    )\n",
    "    print(f\"\\nGemini Evaluation Scores for sample: {gemini_scores}\")\n",
    "\n",
    "    # Calculate average score (ignoring Nones)\n",
    "    valid_scores = [score for score in gemini_scores if score is not None]\n",
    "    if valid_scores:\n",
    "        average_gemini_score = sum(valid_scores) / len(valid_scores)\n",
    "        print(f\"Average Gemini Score for sample: {average_gemini_score:.2f}\")\n",
    "    else:\n",
    "        print(\"No valid scores obtained from Gemini evaluation.\")\n",
    "else:\n",
    "    print(\"Gemini model not initialized. Please run the setup cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e9525",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2f3fc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"../models/model_statedict-23-12-2025_15h06m.pth\", map_location=\"cpu\")\n",
    "\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "868d75a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['tôi bị điên'], ['i was crazy .'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, ['tôi bị điên'], max_generated_token_len=5, beam_size=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1cItDNG8ukuy22da0PRM1gR5P7iypEsZn",
     "timestamp": 1765365277371
    }
   ]
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8947728,
     "sourceId": 14069402,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3201.351754,
   "end_time": "2025-12-15T11:18:43.270742",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-15T10:25:21.918988",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
